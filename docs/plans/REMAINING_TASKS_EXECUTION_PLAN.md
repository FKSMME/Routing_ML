# ë‚¨ì€ ì‘ì—… ì‹¤í–‰ ê³„íš

**ë¬¸ì„œ ID**: RTEP-2025-10-06
**ë²„ì „**: 1.0.0
**ì‘ì„±ì¼**: 2025-10-06
**ì‘ì„±ì**: ML Team

---

## í˜„ì¬ ì§„í–‰ ìƒí™©

**ì™„ë£Œëœ ì‘ì—…**: 12/18 (67%)
**ë‚¨ì€ ì‘ì—…**: 6/18 (33%)

---

## Task #13: CPU ê°€ìƒì„œë²„ ìµœì í™” ê°€ì´ë“œ

### ìš°ì„ ìˆœìœ„
**ê¸´ê¸‰** (1-2ì£¼)

### ëª©ì 
GPU ì—†ì´ CPU ê°€ìƒì„œë²„ì—ì„œ ML ì„±ëŠ¥ ìµœì í™”

### í˜„ì¬ í™˜ê²½
- **ì„œë²„**: CPU ê°€ìƒì„œë²„ (GPU ì—†ìŒ)
- **ì œì•½**: ì˜¨í”„ë ˆë¯¸ìŠ¤, ì˜ˆì‚° ì œí•œ
- **ëª©í‘œ**: CPU ìµœì í™”ë¡œ ì„±ëŠ¥ í–¥ìƒ

### CPU ìµœì í™” ì „ëµ

#### 1. ë©€í‹°ìŠ¤ë ˆë“œ í™œìš©

```python
# HNSW ì¸ë±ìŠ¤ ë¹Œë“œ (ë©€í‹°ìŠ¤ë ˆë“œ)
import nmslib

index = nmslib.init(method='hnsw', space='cosine')
index.addDataPointBatch(embeddings)
index.createIndex(
    {
        'M': 32,
        'efConstruction': 400,
        'post': 2,
        'num_threads': -1,  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
    }
)

# scikit-learn ë³‘ë ¬ ì²˜ë¦¬
from sklearn.ensemble import IsolationForest

model = IsolationForest(
    n_estimators=100,
    n_jobs=-1,  # ëª¨ë“  ì½”ì–´ ì‚¬ìš©
)
```

#### 2. BLAS ë¼ì´ë¸ŒëŸ¬ë¦¬ ìµœì í™”

```bash
# OpenBLAS ì„¤ì¹˜ (CPU ìµœì í™”ëœ ì„ í˜•ëŒ€ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬)
sudo apt-get install libopenblas-dev

# NumPyê°€ OpenBLAS ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
export OPENBLAS_NUM_THREADS=8
export MKL_NUM_THREADS=8

# í™•ì¸
python -c "import numpy as np; np.__config__.show()"
```

#### 3. ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©

```python
# Sentence-BERT ê²½ëŸ‰ ëª¨ë¸ ì„ íƒ
from sentence_transformers import SentenceTransformer

# ê¶Œì¥: MiniLM (384ì°¨ì›, ë¹ ë¦„)
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# ëŒ€ì•ˆ: DistilBERT (768ì°¨ì›, ì¤‘ê°„)
# model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
```

#### 4. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
# ì‘ì€ ë°°ì¹˜ í¬ê¸°ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ í–¥ìƒ
embeddings = model.encode(
    texts,
    batch_size=16,  # 32 â†’ 16 (ë©”ëª¨ë¦¬ ì ˆì•½)
    show_progress_bar=True,
)
```

#### 5. ìºì‹± ì ê·¹ í™œìš©

```python
# Redis ìºì‹±ìœ¼ë¡œ ì¬ê³„ì‚° ë°©ì§€
import redis
import pickle

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_cached_embedding(item_code):
    key = f"embedding:{item_code}"
    cached = redis_client.get(key)
    if cached:
        return pickle.loads(cached)
    return None

def set_cached_embedding(item_code, embedding):
    key = f"embedding:{item_code}"
    redis_client.setex(key, 3600, pickle.dumps(embedding))  # 1ì‹œê°„ TTL
```

### ì˜ˆìƒ íš¨ê³¼ (CPU ìµœì í™”)

| ì‘ì—… | í˜„ì¬ (ë‹¨ì¼ìŠ¤ë ˆë“œ) | ìµœì í™” í›„ (ë©€í‹°ìŠ¤ë ˆë“œ) | ê°œì„ ë¥  |
|-----|-----------------|---------------------|--------|
| HNSW ì¸ë±ìŠ¤ ë¹Œë“œ | 5ë¶„ | 1-2ë¶„ | 60-80% |
| ì„ë² ë”© ìƒì„± (1,000ê°œ) | 30ì´ˆ | 10ì´ˆ | 67% |
| ì´ìƒ íƒì§€ í•™ìŠµ | 2ë¶„ | 30ì´ˆ | 75% |
| API ì‘ë‹µ (ìºì‹œ íˆíŠ¸) | 500ms | 50ms | 90% |

### ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [x] ë©€í‹°ìŠ¤ë ˆë“œ ì„¤ì • (num_threads=-1)
- [ ] OpenBLAS ì„¤ì¹˜ ë° ì„¤ì •
- [ ] ê²½ëŸ‰ Sentence-BERT ëª¨ë¸ ì „í™˜
- [ ] Redis ìºì‹± êµ¬í˜„
- [ ] ë°°ì¹˜ í¬ê¸° íŠœë‹
- [ ] ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (ìµœì í™” ì „í›„ ë¹„êµ)
- [ ] ë¬¸ì„œí™” (CPU ìµœì í™” ê°€ì´ë“œ)

---

## Task #14: ì§€ì‹ ì „ë‹¬ ê³„íš

### ìš°ì„ ìˆœìœ„
**ì¤‘ìš”** (2-4ì£¼)

### ëª©ì 
Bus Factor 1 â†’ 3+ ì¦ê°€, íŒ€ ì—­ëŸ‰ ê°•í™”

### ì§€ì‹ ì „ë‹¬ ëŒ€ìƒ
1. **ì‹ ê·œ ê°œë°œì** (2ëª…)
2. **ë°ì´í„° ì—”ì§€ë‹ˆì–´** (1ëª…)
3. **ìš´ì˜ ë‹´ë‹¹ì** (1ëª…)

### ì „ë‹¬ ë‚´ìš©

#### Week 1: ì‹œìŠ¤í…œ ê°œìš” ë° ì•„í‚¤í…ì²˜
- **êµìœ¡ ìë£Œ**: ONBOARDING_GUIDE.md
- **ì‹¤ìŠµ**: ë¡œì»¬ í™˜ê²½ ì…‹ì—…
- **ì‚°ì¶œë¬¼**: í™˜ê²½ êµ¬ì¶• ì™„ë£Œ ì¸ì¦

#### Week 2: ML íŒŒì´í”„ë¼ì¸ ì´í•´
- **êµìœ¡ ìë£Œ**:
  - trainer/ml/ ë””ë ‰í† ë¦¬ êµ¬ì¡°
  - HNSW ë²¡í„° ê²€ìƒ‰ ì›ë¦¬
  - ë©”íƒ€ ì•™ìƒë¸” ì•Œê³ ë¦¬ì¦˜
- **ì‹¤ìŠµ**:
  - ëª¨ë¸ ì¬í•™ìŠµ
  - ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- **ì‚°ì¶œë¬¼**: í•™ìŠµ ì‹¤í–‰ ë¡œê·¸

#### Week 3: Backend API ë° Frontend
- **êµìœ¡ ìë£Œ**:
  - FastAPI ë¼ìš°í„° êµ¬ì¡°
  - React ì»´í¬ë„ŒíŠ¸ ê³„ì¸µ
  - Zustand ìƒíƒœ ê´€ë¦¬
- **ì‹¤ìŠµ**:
  - API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
  - UI ì»´í¬ë„ŒíŠ¸ ìˆ˜ì •
- **ì‚°ì¶œë¬¼**: PR 1ê°œ ì œì¶œ

#### Week 4: ìš´ì˜ ë° ëª¨ë‹ˆí„°ë§
- **êµìœ¡ ìë£Œ**:
  - Grafana ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•
  - ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ í•´ì„
  - íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ
- **ì‹¤ìŠµ**:
  - ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±
  - ì´ìƒì¹˜ ì¡°ì‚¬
- **ì‚°ì¶œë¬¼**: ì£¼ê°„ ë¦¬í¬íŠ¸ 1íšŒ ìƒì„±

### ì§€ì‹ ì „ë‹¬ ë°©ë²•
- **í˜ì–´ í”„ë¡œê·¸ë˜ë°**: ì£¼ 2íšŒ, 2ì‹œê°„
- **ì½”ë“œ ë¦¬ë·°**: ëª¨ë“  PR ë¦¬ë·°
- **ì£¼ê°„ ë°œí‘œ**: í•™ìŠµ ë‚´ìš© ê³µìœ 
- **ë¬¸ì„œí™”**: í•™ìŠµ ë‚´ìš© Wiki ì •ë¦¬

### ì„±ê³µ ê¸°ì¤€
- **Bus Factor**: 1 â†’ 3 ì´ìƒ
- **ì‹ ê·œ ê°œë°œì ë…ë¦½ ì‘ì—…**: 4ì£¼ ë‚´
- **ë¬¸ì„œ ì»¤ë²„ë¦¬ì§€**: 90% ì´ìƒ
- **íŒ€ ë§Œì¡±ë„**: 4.0/5.0 ì´ìƒ

---

## Task #15: Docker ì»¨í…Œì´ë„ˆí™”

### ìš°ì„ ìˆœìœ„
**ì¤‘ìš”** (2-4ì£¼)

### ëª©ì 
ë°°í¬ ì¼ê´€ì„±, í™˜ê²½ ê²©ë¦¬, í™•ì¥ì„± í–¥ìƒ

### ì»¨í…Œì´ë„ˆ êµ¬ì¡°

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Backend API
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DB_TYPE=MSSQL
      - MSSQL_HOST=db
      - MSSQL_PASSWORD=${MSSQL_PASSWORD}
    volumes:
      - ./models:/app/models
      - ./reports:/app/reports
    depends_on:
      - db
      - redis

  # Frontend Prediction
  frontend-prediction:
    build: ./frontend-prediction
    ports:
      - "5173:80"
    environment:
      - VITE_API_URL=http://localhost:8000

  # Frontend Training
  frontend-training:
    build: ./frontend-training
    ports:
      - "5174:80"
    environment:
      - VITE_API_URL=http://localhost:8000

  # PostgreSQL (ë§ˆì´ê·¸ë ˆì´ì…˜ í›„)
  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=routing_ml
      - POSTGRES_USER=routing_user
      - POSTGRES_PASSWORD=${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  # Redis (ìºì‹±)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  # Grafana (ëª¨ë‹ˆí„°ë§)
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning

  # Prometheus (ë©”íŠ¸ë¦­)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

volumes:
  postgres_data:
  grafana_data:
```

### Dockerfile ì˜ˆì‹œ

```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    unixodbc-dev \
    && rm -rf /var/lib/apt/lists/*

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8000/api/health || exit 1

# ì‹¤í–‰
CMD ["uvicorn", "backend.api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Dockerfile ì‘ì„± (backend, frontend-prediction, frontend-training)
- [ ] docker-compose.yml ì‘ì„±
- [ ] .dockerignore ì‘ì„±
- [ ] í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬ (.env.example)
- [ ] ë³¼ë¥¨ ë§ˆìš´íŠ¸ ì„¤ì • (ëª¨ë¸, ë°ì´í„°)
- [ ] í—¬ìŠ¤ì²´í¬ êµ¬í˜„
- [ ] ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œí™” (README.Docker.md)

---

## Task #16: CI/CD íŒŒì´í”„ë¼ì¸ ê°•í™”

### ìš°ì„ ìˆœìœ„
**ê¶Œì¥** (1-3ê°œì›”)

### ëª©ì 
ìë™í™”ëœ í…ŒìŠ¤íŠ¸, ë¹Œë“œ, ë°°í¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### GitHub Actions ì›Œí¬í”Œë¡œìš°

#### 1. í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ (.github/workflows/test.yml)

```yaml
name: Test

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  backend-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run tests
        run: pytest --cov=backend tests/
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  frontend-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      - name: Install dependencies
        run: npm ci
        working-directory: frontend-prediction
      - name: Run tests
        run: npm test
        working-directory: frontend-prediction
      - name: Type check
        run: npm run type-check
        working-directory: frontend-prediction
```

#### 2. ë¹Œë“œ íŒŒì´í”„ë¼ì¸ (.github/workflows/build.yml)

```yaml
name: Build

on:
  push:
    tags:
      - 'v*'

jobs:
  build-docker:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      - name: Login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      - name: Build and push
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          push: true
          tags: routingml/backend:${{ github.ref_name }}
```

#### 3. ë°°í¬ íŒŒì´í”„ë¼ì¸ (.github/workflows/deploy.yml)

```yaml
name: Deploy

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        type: choice
        options:
          - staging
          - production

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}
    steps:
      - uses: actions/checkout@v3
      - name: Deploy to server
        run: |
          ssh ${{ secrets.SERVER_USER }}@${{ secrets.SERVER_HOST }} \
            "cd /app/routing-ml && \
             docker-compose pull && \
             docker-compose up -d"
```

### ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš° ì‘ì„± (test, build, deploy)
- [ ] ì‹œí¬ë¦¿ ì„¤ì • (DOCKER_USERNAME, SERVER_HOST ë“±)
- [ ] í™˜ê²½ë³„ ì„¤ì • (staging, production)
- [ ] ë°°í¬ ìŠ¹ì¸ í”„ë¡œì„¸ìŠ¤
- [ ] ë¡¤ë°± ì „ëµ
- [ ] ì•Œë¦¼ ì„¤ì • (Slack, Email)

---

## Task #17: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 

### ìš°ì„ ìˆœìœ„
**ê¶Œì¥** (1-3ê°œì›”)

### ëª©ì 
ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë³‘ëª© ì§€ì  ì‹ë³„

### ì£¼ìš” ë©”íŠ¸ë¦­

#### 1. API ì„±ëŠ¥ ë©”íŠ¸ë¦­

```python
# backend/api/middleware/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# API ìš”ì²­ ì¹´ìš´í„°
api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

# API ì§€ì—°ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
api_latency_seconds = Histogram(
    'api_latency_seconds',
    'API latency in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0]
)

# í™œì„± ì—°ê²° ìˆ˜
active_connections = Gauge(
    'active_connections',
    'Number of active connections'
)

# ë¯¸ë“¤ì›¨ì–´
async def metrics_middleware(request, call_next):
    start = time.time()
    active_connections.inc()

    try:
        response = await call_next(request)
        latency = time.time() - start

        api_requests_total.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).inc()

        api_latency_seconds.labels(
            method=request.method,
            endpoint=request.url.path
        ).observe(latency)

        return response
    finally:
        active_connections.dec()
```

#### 2. ML ì„±ëŠ¥ ë©”íŠ¸ë¦­

```python
# ê²€ìƒ‰ ì„±ëŠ¥
vector_search_latency = Histogram(
    'vector_search_latency_seconds',
    'Vector search latency',
    buckets=[0.01, 0.05, 0.1, 0.2, 0.5, 1.0]
)

# ì˜ˆì¸¡ ì •í™•ë„
prediction_accuracy = Gauge(
    'prediction_accuracy',
    'Prediction accuracy (top-k recall)'
)

# ëª¨ë¸ ë²„ì „
model_version = Gauge(
    'model_version_info',
    'Model version',
    ['version', 'trained_at']
)
```

#### 3. ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­

```python
# í’ˆì§ˆ ì ìˆ˜
data_quality_score = Gauge(
    'data_quality_score',
    'Data quality score (0-100)'
)

# ì´ìƒì¹˜ ë¹„ìœ¨
anomaly_rate = Gauge(
    'anomaly_rate',
    'Anomaly rate (0-1)'
)

# Critical ì´ìŠˆ ìˆ˜
critical_issues = Gauge(
    'critical_issues_count',
    'Number of critical issues'
)
```

### Grafana ëŒ€ì‹œë³´ë“œ

**ëŒ€ì‹œë³´ë“œ êµ¬ì„±**:
1. **ì‹œìŠ¤í…œ ê°œìš”**
   - API ìš”ì²­/ì´ˆ
   - í‰ê·  ì‘ë‹µ ì‹œê°„
   - ì—ëŸ¬ìœ¨
   - í™œì„± ì—°ê²° ìˆ˜

2. **ML ì„±ëŠ¥**
   - ê²€ìƒ‰ ì§€ì—°ì‹œê°„ ë¶„í¬
   - ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì´
   - ëª¨ë¸ ë²„ì „ ì •ë³´

3. **ë°ì´í„° í’ˆì§ˆ**
   - í’ˆì§ˆ ì ìˆ˜ ì¶”ì´
   - ì´ìƒì¹˜ ë¹„ìœ¨
   - ì´ìŠˆ í˜„í™©

4. **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰**
   - CPU ì‚¬ìš©ë¥ 
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
   - ë””ìŠ¤í¬ I/O

### ì•Œë¦¼ ê·œì¹™

```yaml
# monitoring/alerts.yml
groups:
  - name: api_alerts
    interval: 1m
    rules:
      - alert: HighLatency
        expr: api_latency_seconds{quantile="0.95"} > 1
        for: 5m
        annotations:
          summary: "API ì§€ì—°ì‹œê°„ ë†’ìŒ (>1ì´ˆ)"

      - alert: HighErrorRate
        expr: rate(api_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        annotations:
          summary: "ì—ëŸ¬ìœ¨ 5% ì´ˆê³¼"

      - alert: LowDataQuality
        expr: data_quality_score < 70
        for: 10m
        annotations:
          summary: "ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ 70ì  ë¯¸ë§Œ"
```

---

## Task #18: ì¶”ê°€ ê°œì„ ì‚¬í•­

### ìš°ì„ ìˆœìœ„
**ì„ íƒ** (í•„ìš” ì‹œ)

### ê°œì„  ì•„ì´ë””ì–´

#### 1. ìë™ ì¬í•™ìŠµ íŒŒì´í”„ë¼ì¸
- **ìŠ¤ì¼€ì¤„**: ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 2ì‹œ
- **íŠ¸ë¦¬ê±°**: ë°ì´í„° ë³€í™” 10% ì´ìƒ
- **ê²€ì¦**: A/B í…ŒìŠ¤íŠ¸ë¡œ ì„±ëŠ¥ ë¹„êµ
- **ë¡¤ë°±**: ì„±ëŠ¥ ì €í•˜ ì‹œ ì´ì „ ëª¨ë¸ë¡œ ë³µì›

#### 2. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
- **UI**: ì˜ˆì¸¡ ê²°ê³¼ì— ğŸ‘ğŸ‘ ë²„íŠ¼
- **ì €ì¥**: feedback í…Œì´ë¸”ì— ì €ì¥
- **ë¶„ì„**: ì£¼ê°„ ë¦¬í¬íŠ¸ì— ë§Œì¡±ë„ í¬í•¨
- **í™œìš©**: ëª¨ë¸ ì¬í•™ìŠµ ì‹œ ê°€ì¤‘ì¹˜ ì¡°ì •

#### 3. ë‹¤êµ­ì–´ ì§€ì› (ì˜ë¬¸)
- **i18n ë¼ì´ë¸ŒëŸ¬ë¦¬**: react-i18next
- **ë²ˆì—­ íŒŒì¼**: locales/en.json, locales/ko.json
- **UI**: ì–¸ì–´ ì„ íƒ ë“œë¡­ë‹¤ìš´
- **API**: Accept-Language í—¤ë” ì§€ì›

#### 4. ëª¨ë°”ì¼ ë°˜ì‘í˜• ìµœì í™”
- **ë¸Œë ˆì´í¬í¬ì¸íŠ¸**: 768px, 1024px, 1440px
- **ë ˆì´ì•„ì›ƒ**: ëª¨ë°”ì¼ì—ì„œ ì„¸ë¡œ ìŠ¤íƒ
- **í„°ì¹˜ ì œìŠ¤ì²˜**: ìŠ¤ì™€ì´í”„ ë„¤ë¹„ê²Œì´ì…˜
- **ì„±ëŠ¥**: ì´ë¯¸ì§€ lazy loading

#### 5. ì˜¤í”„ë¼ì¸ ëª¨ë“œ (PWA)
- **Service Worker**: ìºì‹± ì „ëµ
- **IndexedDB**: ë¡œì»¬ ë°ì´í„° ì €ì¥
- **ë™ê¸°í™”**: ì˜¨ë¼ì¸ ë³µê·€ ì‹œ ì„œë²„ ë™ê¸°í™”

---

## ì‹¤í–‰ ìš°ì„ ìˆœìœ„ ìš”ì•½

### ì¦‰ì‹œ (1-2ì£¼) ğŸ”´
- âœ… Task #13: GPU ì„œë²„ ì„¸íŒ… (ì„±ëŠ¥ 10ë°° í–¥ìƒ)

### ë‹¨ê¸° (2-4ì£¼) ğŸŸ¡
- âœ… Task #14: ì§€ì‹ ì „ë‹¬ ê³„íš (Bus Factor í•´ê²°)
- âœ… Task #15: Docker ì»¨í…Œì´ë„ˆí™” (ë°°í¬ ì¼ê´€ì„±)

### ì¤‘ê¸° (1-3ê°œì›”) ğŸŸ¢
- âœ… Task #16: CI/CD íŒŒì´í”„ë¼ì¸ (ìë™í™”)
- âœ… Task #17: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì  (ëª¨ë‹ˆí„°ë§)

### ì¥ê¸° (í•„ìš” ì‹œ) âšª
- âœ… Task #18: ì¶”ê°€ ê°œì„ ì‚¬í•­ (UX í–¥ìƒ)

---

## ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¬¸ì„œ
- [x] Phase 1 ë²”ìœ„ ì •ì˜ì„œ
- [x] ì˜¨ë³´ë”© ê°€ì´ë“œ
- [x] PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ
- [x] UI ê°œì„  ê³„íš
- [x] íŠœí† ë¦¬ì–¼ ë¹„ë””ì˜¤ ê°€ì´ë“œ
- [x] íŒŒì¼ëŸ¿ í”„ë¡œê·¸ë¨ ê³„íš
- [x] ë²¡í„° ê²€ìƒ‰ ìµœì í™” ê°€ì´ë“œ
- [ ] GPU ì„œë²„ ì„¸íŒ… ê°€ì´ë“œ (ë³¸ ë¬¸ì„œ í¬í•¨)
- [ ] Docker ë°°í¬ ê°€ì´ë“œ
- [ ] CI/CD íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ

### ì½”ë“œ
- [x] ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜ (Isolation Forest)
- [x] ì£¼ê°„ ë¦¬í¬íŠ¸ ìë™í™”
- [x] ì˜¨í”„ë ˆë¯¸ìŠ¤ NLP
- [x] ë°ì´í„° í’ˆì§ˆ ëŒ€ì‹œë³´ë“œ
- [ ] GPU ê°€ì† ë²¡í„° ê²€ìƒ‰
- [ ] Docker ì„¤ì •
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš°
- [ ] Prometheus ë©”íŠ¸ë¦­

### ì¸í”„ë¼
- [ ] GPU ì„œë²„ êµ¬ë§¤/í• ë‹¹
- [ ] Docker í™˜ê²½ êµ¬ì¶•
- [ ] GitHub Actions ì„¤ì •
- [ ] Grafana ëŒ€ì‹œë³´ë“œ ë°°í¬
- [ ] ì•Œë¦¼ ì±„ë„ ì„¤ì • (Slack)

---

**ë¬¸ì„œ ì¢…ë£Œ**

**ì‘ì„±ì**: ML Team
**ë‹¤ìŒ ì•¡ì…˜**: GPU ì„œë²„ ì˜ˆì‚° ìŠ¹ì¸ ìš”ì²­
