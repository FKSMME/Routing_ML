from __future__ import annotations

import atexit
import time
from pathlib import Path
import threading
from contextlib import contextmanager
import warnings
from typing import Any, Dict, List, Sequence

import pandas as pd
import pyodbc

from common.logger import get_logger

logger = get_logger("database")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0) ê²½ë¡œ Â· ë·° ìƒìˆ˜ (ë¨¼ì € ì •ì˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BASE_DIR   = Path(__file__).resolve().parents[1]     # e.g., machine/
ACCESS_DIR = BASE_DIR / "routing_data"               # Access DB í´ë”

VIEW_ITEM_MASTER = "dbo_BI_ITEM_INFO_VIEW"
VIEW_ROUTING     = "dbo_BI_ROUTING_VIEW"
VIEW_WORK_RESULT = "dbo_BI_WORK_ORDER_RESULTS"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1) "ê°€ì¥ ìµœê·¼ Access DB" ê²½ë¡œ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _latest_db(path: Path | str) -> Path:
    """<routing_data> ì•ˆì—ì„œ ìµœì‹  *.accdb / *.mdb íŒŒì¼ ë°˜í™˜"""
    p = Path(path).expanduser()
    if not p.exists():
        raise FileNotFoundError(f"í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ â” {p}")
    files = sorted(
        list(p.glob("*.accdb")) + list(p.glob("*.mdb")),
        key=lambda f: f.stat().st_mtime,
        reverse=True,
    )
    if not files:
        raise FileNotFoundError(f"*.accdb / *.mdb íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ â” {p}")
    latest = files[0]
    logger.debug("[DB] ìµœì‹  Access ì„ íƒ: %s", latest.name)
    return latest

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2) ê¸°ë³¸ ì—°ê²° í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _create_connection() -> pyodbc.Connection:
    """ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒì„±"""
    db_path = _latest_db(ACCESS_DIR)
    conn_str = (
        r"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};"
        fr"DBQ={db_path}"
    )
    try:
        return pyodbc.connect(conn_str, timeout=10)
    except pyodbc.Error as exc:
        raise ConnectionError(f"Access DB ì—°ê²° ì‹¤íŒ¨: {exc}") from exc

def _connect() -> pyodbc.Connection:
    """ê°€ì¥ ìµœì‹  Access DBì— ì—°ê²° (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    return _create_connection()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3) ì—°ê²° í’€ë§ í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class ConnectionPool:
    """ê°„ë‹¨í•œ ì—°ê²° í’€"""
    def __init__(self, max_connections=5):
        self.max_connections = max_connections
        self.connections = []
        self.lock = threading.Lock()
    
    @contextmanager
    def get_connection(self):
        """ì—°ê²° íšë“"""
        conn = None
        try:
            with self.lock:
                if self.connections:
                    conn = self.connections.pop()
                    # ì—°ê²° ìƒíƒœ í™•ì¸
                    try:
                        conn.execute("SELECT 1")  # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
                    except Exception:
                        # ì—°ê²°ì´ ëŠì–´ì¡Œìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                        try:
                            conn.close()
                        except Exception:
                            pass
                        conn = None
                
                if conn is None:
                    conn = _create_connection()  # ìƒˆ ì—°ê²° ìƒì„±
            yield conn
        except Exception:
            # ì—°ê²°ì— ë¬¸ì œê°€ ìˆìœ¼ë©´ ë‹«ê¸°
            if conn:
                try:
                    conn.close()
                except Exception:
                    pass
            raise
        finally:
            if conn:
                try:
                    with self.lock:
                        if len(self.connections) < self.max_connections:
                            self.connections.append(conn)
                        else:
                            conn.close()
                except Exception as e:
                    logger.warning(f"ì—°ê²° ë°˜í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                    try:
                        conn.close()
                    except Exception:
                        pass

# ì „ì—­ ì—°ê²° í’€
_connection_pool = ConnectionPool()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4) ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def set_debug_mode(enabled: bool = True):
    """ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •"""
    import logging
    level = logging.DEBUG if enabled else logging.INFO
    
    # ëª¨ë“  ê´€ë ¨ ë¡œê±°ì˜ ë ˆë²¨ ë³€ê²½
    loggers = ['database', 'predictor_ml_improved']
    for logger_name in loggers:
        try:
            target_logger = logging.getLogger(logger_name)
            target_logger.setLevel(level)
            for handler in target_logger.handlers:
                handler.setLevel(level)
        except Exception as e:
            logger.warning(f"ë¡œê±° ì„¤ì • ì‹¤íŒ¨ {logger_name}: {e}")
    
    print(f"ë””ë²„ê·¸ ëª¨ë“œ: {'ON' if enabled else 'OFF'}")

def validate_system_requirements():
    """ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦"""
    issues = []
    
    # 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
    try:
        __import__("pandas")
        __import__("numpy")
    except ImportError as e:
        issues.append(f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
    
    # 2. Access ë“œë¼ì´ë²„ í™•ì¸
    try:
        drivers = pyodbc.drivers()
        access_drivers = [d for d in drivers if 'Access' in d]
        if not access_drivers:
            issues.append("Microsoft Access ODBC ë“œë¼ì´ë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        else:
            logger.info(f"ë°œê²¬ëœ Access ë“œë¼ì´ë²„: {access_drivers}")
    except Exception as e:
        issues.append(f"ODBC ë“œë¼ì´ë²„ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # 3. ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í™•ì¸
    try:
        db_path = _latest_db(ACCESS_DIR)
        if not db_path.exists():
            issues.append(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì—†ìŒ: {db_path}")
        else:
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ í™•ì¸: {db_path}")
    except Exception as e:
        issues.append(f"ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    if issues:
        for issue in issues:
            logger.error(f"ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ë¬¸ì œ: {issue}")
        return False, issues
    else:
        logger.info("ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­ ê²€ì¦ ì™„ë£Œ")
        return True, []

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5) ì¿¼ë¦¬ ì‹¤í–‰ í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _run_query_optimized(query: str, params: Sequence[Any] | None = None, retries: int = 3, delay: float = 2.0) -> pd.DataFrame:
    """ìµœì í™”ëœ ì¿¼ë¦¬ ì‹¤í–‰ (ì—°ê²° í’€ ì‚¬ìš©)"""
    for attempt in range(1, retries + 1):
        try:
            with _connection_pool.get_connection() as conn:
                with warnings.catch_warnings():
                    warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy connectable')
                    df = pd.read_sql(query, conn, params=params or [])
            
            if df.empty:
                logger.debug("[DB] ë¹ˆ ê²°ê³¼ì„¸íŠ¸ ë°˜í™˜ â€“ %s", query[:80])
            return df
            
        except Exception as exc:
            if attempt < retries:
                logger.warning(f"[DB] ì¿¼ë¦¬ ì¬ì‹œë„ {attempt}/{retries}: {exc}")
                time.sleep(delay)
                continue
            raise RuntimeError(f"[DB] ì¿¼ë¦¬ ì‹¤íŒ¨: {exc}") from exc

def _run_query(
    query: str,
    params: Sequence[Any] | None = None,
    retries: int = 3,
    delay: float = 2.0,
) -> pd.DataFrame:
    """ì¿¼ë¦¬ ì‹¤í–‰ â†’ DataFrame (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)"""
    for attempt in range(1, retries + 1):
        try:
            with _connect() as conn:
                # pandas ê²½ê³  ì–µì œ
                with warnings.catch_warnings():
                    warnings.filterwarnings('ignore', 
                                          message='pandas only supports SQLAlchemy connectable')
                    df = pd.read_sql(query, conn, params=params or [])
            if df.empty:
                logger.warning("[DB] ë¹ˆ ê²°ê³¼ì„¸íŠ¸ ë°˜í™˜ â€“ %s", query[:80])
            return df
        except Exception as exc:
            if attempt < retries:
                logger.warning(f"[DB] ì¿¼ë¦¬ ì¬ì‹œë„ {attempt}/{retries}: {exc}")
                time.sleep(delay)
                continue
            raise RuntimeError(f"[DB] ì¿¼ë¦¬ ì‹¤íŒ¨: {exc}") from exc

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6) ê³µê°œ API - ë‹¨ì¼ ì¡°íšŒ (í•„ìˆ˜ í•¨ìˆ˜ë“¤)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def fetch_item_master(columns: list[str] | None = None) -> pd.DataFrame:
    """ì „ì²´ í’ˆëª© ë§ˆìŠ¤í„° ì¡°íšŒ"""
    col_clause = ", ".join(columns) if columns else "*"
    query = f"SELECT {col_clause} FROM {VIEW_ITEM_MASTER}"
    logger.info("[DB] ITEM_MASTER ì¡°íšŒâ€¦")
    return _run_query(query)

def fetch_single_item(item_cd: str) -> pd.DataFrame:
    """ë‹¨ì¼ í’ˆëª© ì •ë³´ ì¡°íšŒ - ëŒ€ì†Œë¬¸ì ë¬´ì‹œ"""
    logger.debug(f"[DB] ITEM ë‹¨ê±´ ì¡°íšŒ: {item_cd}")
    
    # ëŒ€ë¬¸ìë¡œ í†µì¼í•˜ì—¬ ì¡°íšŒ
    item_cd_upper = item_cd.upper().strip()
    
    query = f"""
        SELECT *
        FROM {VIEW_ITEM_MASTER}
        WHERE ITEM_CD = ?
    """
    
    try:
        df = _run_query(query, [item_cd_upper])
        
        if df.empty:
            # LIKE ê²€ìƒ‰ìœ¼ë¡œ ì¬ì‹œë„
            query_like = f"""
                SELECT *
                FROM {VIEW_ITEM_MASTER}
                WHERE ITEM_CD LIKE ?
            """
            df = _run_query(query_like, [f'%{item_cd_upper}%'])
            
            if not df.empty and len(df) == 1:
                logger.info(f"[DB] LIKE ê²€ìƒ‰ìœ¼ë¡œ í’ˆëª© ë°œê²¬: {df['ITEM_CD'].iloc[0]}")
                
        return df
        
    except Exception as e:
        logger.error(f"[DB] í’ˆëª© ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

def fetch_routing_for_item(item_cd: str, latest_only: bool = True, selection_mode: str = "latest") -> pd.DataFrame:
    """
    íŠ¹ì • í’ˆëª©ì˜ ë¼ìš°íŒ… ì •ë³´ ì¡°íšŒ - ëŒ€ì†Œë¬¸ì ë¬´ì‹œ
    
    Args:
        item_cd: í’ˆëª© ì½”ë“œ
        latest_only: Trueì¼ ê²½ìš° í•˜ë‚˜ì˜ ROUT_NOë§Œ ë°˜í™˜ (ê¸°ë³¸ê°’ True)
        selection_mode: "latest" (ìµœì‹ ) ë˜ëŠ” "most_used" (ìµœë‹¤ ì‚¬ìš©)
    
    Returns:
        pd.DataFrame: ë¼ìš°íŒ… ì •ë³´
    """
    logger.debug(f"[DB] ROUTING ì¡°íšŒ: {item_cd} (latest_only={latest_only}, mode={selection_mode})")
    
    # ëŒ€ë¬¸ìë¡œ í†µì¼í•˜ì—¬ ì¡°íšŒ
    item_cd_upper = item_cd.upper().strip()
    
    if latest_only:
        try:
            if selection_mode == "most_used":
                # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ ROUT_NO ì°¾ê¸°
                count_query = f"""
                    SELECT ROUT_NO, COUNT(*) as PROC_COUNT
                    FROM {VIEW_ROUTING}
                    WHERE ITEM_CD = ?
                    GROUP BY ROUT_NO
                    ORDER BY COUNT(*) DESC, ROUT_NO DESC
                """
                
                count_df = _run_query(count_query, [item_cd_upper])
                
                if count_df.empty:
                    logger.warning(f"[DB] ROUT_NOë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ â€“ ITEM_CD: {item_cd}")
                    return pd.DataFrame()
                
                # ê°€ì¥ ë§ì€ ê³µì •ì„ ê°€ì§„ ROUT_NO ì„ íƒ
                most_used_rout_no = count_df.iloc[0]['ROUT_NO']
                
                logger.info(f"[DB] ìµœë‹¤ ê³µì • ROUT_NO ì„ íƒ: {most_used_rout_no} ({count_df.iloc[0]['PROC_COUNT']}ê°œ ê³µì •)")
                
                # ë””ë²„ê¹…: ëª¨ë“  ROUT_NOì™€ ê³µì • ìˆ˜ ì¶œë ¥
                logger.debug(f"[DB] {item_cd}ì˜ ROUT_NOë³„ ê³µì • ìˆ˜:")
                for idx, row in count_df.iterrows():
                    logger.debug(f"  - ROUT_NO: {row['ROUT_NO']}, ê³µì • ìˆ˜: {row['PROC_COUNT']}")
                
                # í•´ë‹¹ ROUT_NOì˜ ëª¨ë“  ê³µì • ì¡°íšŒ
                query = f"""
                    SELECT *
                    FROM {VIEW_ROUTING}
                    WHERE ITEM_CD = ? AND ROUT_NO = ?
                    ORDER BY PROC_SEQ
                """
                
                df = _run_query(query, [item_cd_upper, most_used_rout_no])
                
            else:  # latest ëª¨ë“œ (ê¸°ì¡´ ë¡œì§)
                # ë¨¼ì € í•´ë‹¹ í’ˆëª©ì˜ ëª¨ë“  ë¼ìš°íŒ… ì •ë³´ë¥¼ ê°€ì ¸ì˜´
                all_routing_query = f"""
                    SELECT DISTINCT ROUT_NO, INSRT_DT
                    FROM {VIEW_ROUTING}
                    WHERE ITEM_CD = ?
                    ORDER BY INSRT_DT DESC, ROUT_NO DESC
                """
                
                rout_df = _run_query(all_routing_query, [item_cd_upper])
                
                if rout_df.empty:
                    logger.warning(f"[DB] ROUT_NOë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ â€“ ITEM_CD: {item_cd}")
                    return pd.DataFrame()
                
                # Pythonì—ì„œ ìµœì‹  ROUT_NO ì„ íƒ
                if 'INSRT_DT' in rout_df.columns:
                    try:
                        # INSRT_DTë¡œ ì •ë ¬ ì‹œë„
                        rout_df['INSRT_DT_SAFE'] = pd.to_datetime(rout_df['INSRT_DT'], errors='coerce')
                        rout_df_sorted = rout_df.sort_values(['INSRT_DT_SAFE', 'ROUT_NO'], 
                                                            ascending=[False, False], 
                                                            na_position='last')
                        latest_rout_no = rout_df_sorted.iloc[0]['ROUT_NO']
                        
                        # ë””ë²„ê¹…: ëª¨ë“  ROUT_NO ì¶œë ¥
                        logger.debug(f"[DB] {item_cd}ì˜ ROUT_NO ëª©ë¡ (ìµœì‹ ìˆœ):")
                        for idx, row in rout_df_sorted.iterrows():
                            date_str = row['INSRT_DT'] if pd.notna(row['INSRT_DT']) else 'N/A'
                            logger.debug(f"  - ROUT_NO: {row['ROUT_NO']}, INSRT_DT: {date_str}")
                            
                    except Exception as e:
                        logger.warning(f"[DB] INSRT_DT ì •ë ¬ ì‹¤íŒ¨, ROUT_NOë¡œë§Œ ì •ë ¬: {e}")
                        # ROUT_NOë¡œë§Œ ì •ë ¬ (ì•ŒíŒŒë²³/ìˆ«ì ë‚´ë¦¼ì°¨ìˆœ)
                        latest_rout_no = rout_df.sort_values('ROUT_NO', ascending=False).iloc[0]['ROUT_NO']
                else:
                    # INSRT_DT ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ROUT_NOë¡œë§Œ ì •ë ¬
                    latest_rout_no = rout_df.sort_values('ROUT_NO', ascending=False).iloc[0]['ROUT_NO']
                
                logger.info(f"[DB] ìµœì‹  ROUT_NO ì„ íƒ: {latest_rout_no}")
                
                # í•´ë‹¹ ROUT_NOì˜ ëª¨ë“  ê³µì • ì¡°íšŒ
                query = f"""
                    SELECT *
                    FROM {VIEW_ROUTING}
                    WHERE ITEM_CD = ? AND ROUT_NO = ?
                    ORDER BY PROC_SEQ
                """
                
                df = _run_query(query, [item_cd_upper, latest_rout_no])
            
            if not df.empty:
                # PROC_SEQ í™•ì¸
                proc_seqs = df['PROC_SEQ'].unique()
                logger.info(f"[DB] ë¼ìš°íŒ… ì¡°íšŒ ì„±ê³µ: ROUT_NO={df['ROUT_NO'].iloc[0]}, {len(df)}ê°œ ê³µì •")
                logger.debug(f"[DB] PROC_SEQ ëª©ë¡: {sorted(proc_seqs)}")
            
            return df
            
        except Exception as e:
            logger.error(f"[DB] ë¼ìš°íŒ… ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    else:
        # ê¸°ì¡´ ë¡œì§: ëª¨ë“  ë¼ìš°íŒ… ì¡°íšŒ
        query = f"""
            SELECT *
            FROM {VIEW_ROUTING}
            WHERE ITEM_CD = ?
            ORDER BY ROUT_NO, PROC_SEQ
        """
        
        try:
            df = _run_query(query, [item_cd_upper])
            
            if df.empty:
                logger.warning(f"[DB] ë¹ˆ ê²°ê³¼ì„¸íŠ¸ ë°˜í™˜ â€“ ITEM_CD: {item_cd}")
            else:
                # ROUT_NOë³„ í†µê³„ ë¡œê¹…
                rout_counts = df['ROUT_NO'].value_counts()
                logger.info(f"[DB] ë¼ìš°íŒ… ì¡°íšŒ ì„±ê³µ: ì´ {len(df)}ê°œ ê³µì •, {len(rout_counts)}ê°œ ROUT_NO")
                for rout_no, count in rout_counts.items():
                    logger.debug(f"  - ROUT_NO: {rout_no}, ê³µì • ìˆ˜: {count}")
                
        except Exception as e:
            logger.error(f"[DB] ë¼ìš°íŒ… ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    return df

def fetch_work_results_for_item(item_cd: str) -> pd.DataFrame:
    """ë‹¨ì¼ í’ˆëª©ì˜ ì‘ì—… ê²°ê³¼ ì¡°íšŒ"""
    query = f"SELECT * FROM {VIEW_WORK_RESULT} WHERE ITEM_CD = ?"
    logger.debug("[DB] WORK_RESULT ì¡°íšŒ: %s", item_cd)
    return _run_query(query, [item_cd.upper()])  # ëŒ€ë¬¸ì ë³€í™˜ ì¶”ê°€

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7) ğŸš€ ë°°ì¹˜ ì¿¼ë¦¬ API (ê³ ì† ì„±ëŠ¥ ìµœì í™”ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_items_batch(item_codes: List[str]) -> Dict[str, pd.DataFrame]:
    """ğŸš€ ì—¬ëŸ¬ í’ˆëª©ì˜ ë§ˆìŠ¤í„° ì •ë³´ë¥¼ í•œ ë²ˆì— ì¡°íšŒ - pandas ê²½ê³  ì–µì œ"""
    if not item_codes:
        return {}
    
    item_codes = [code.upper() for code in item_codes]
    
    batch_size = 100
    all_results = {}
    
    for i in range(0, len(item_codes), batch_size):
        batch_codes = item_codes[i:i + batch_size]
        placeholders = ','.join('?' * len(batch_codes))
        
        query = f'''
            SELECT *
            FROM {VIEW_ITEM_MASTER}
            WHERE ITEM_CD IN ({placeholders})
        '''
        
        logger.info("[DB] ITEM_MASTER ë°°ì¹˜ ì¡°íšŒ: %sê°œ í’ˆëª© (ë°°ì¹˜ %s)", 
                   len(batch_codes), i // batch_size + 1)
        
        try:
            df = _run_query_optimized(query, batch_codes)
                
            if not df.empty:
                for item_cd in batch_codes:
                    item_data = df[df['ITEM_CD'] == item_cd].copy()
                    all_results[item_cd] = item_data
            else:
                for item_cd in batch_codes:
                    all_results[item_cd] = pd.DataFrame()
                    
        except Exception as exc:
            logger.error("[DB] í’ˆëª© ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤íŒ¨ (ë°°ì¹˜ %s): %s", i // batch_size + 1, exc)
            for item_cd in batch_codes:
                all_results[item_cd] = pd.DataFrame()
    
    found_count = len([k for k, v in all_results.items() if not v.empty])
    logger.info("[DB] í’ˆëª© ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: %sê°œ ìš”ì²­, %sê°œ ë°œê²¬", 
               len(item_codes), found_count)
    
    return all_results

def fetch_routings_for_items(item_codes: List[str], latest_only: bool = True) -> Dict[str, pd.DataFrame]:
    """ğŸš€ ì—¬ëŸ¬ í’ˆëª©ì˜ ë¼ìš°íŒ… ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì¡°íšŒ"""
    if not item_codes:
        return {}
    
    item_codes = [code.upper() for code in item_codes]
    
    if latest_only:
        # ê°œë³„ ì¡°íšŒ ë°©ì‹ (ìµœì‹  ROUT_NO ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ)
        all_results = {}
        
        for item_cd in item_codes:
            try:
                routing_df = fetch_routing_for_item(item_cd, latest_only=True)
                all_results[item_cd] = routing_df
            except Exception as e:
                logger.error(f"[DB] {item_cd} ë¼ìš°íŒ… ì¡°íšŒ ì‹¤íŒ¨: {e}")
                all_results[item_cd] = pd.DataFrame()
        
        found_count = len([k for k, v in all_results.items() if not v.empty])
        logger.info(f"[DB] ë¼ìš°íŒ… ê°œë³„ ì¡°íšŒ ì™„ë£Œ (latest_only): {len(item_codes)}ê°œ ìš”ì²­, {found_count}ê°œ ë°œê²¬")
        
        return all_results
    
    # ëª¨ë“  ë¼ìš°íŒ… ì¡°íšŒëŠ” ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 100
    all_results = {}
    
    for i in range(0, len(item_codes), batch_size):
        batch_codes = item_codes[i:i + batch_size]
        placeholders = ','.join('?' * len(batch_codes))
        
        query = f'''
            SELECT *
            FROM {VIEW_ROUTING}
            WHERE ITEM_CD IN ({placeholders})
            ORDER BY ITEM_CD, ROUT_NO, PROC_SEQ
        '''
        
        logger.debug("[DB] ROUTING ë°°ì¹˜ ì¡°íšŒ: %sê°œ í’ˆëª© (ë°°ì¹˜ %s)", 
                    len(batch_codes), i // batch_size + 1)
        
        try:
            df = _run_query_optimized(query, batch_codes)
                
            if not df.empty:
                for item_cd in batch_codes:
                    item_routing = df[df['ITEM_CD'] == item_cd].copy()
                    if not item_routing.empty:
                        rout_counts = item_routing['ROUT_NO'].value_counts()
                        if len(rout_counts) > 1:
                            logger.debug(f"[DB] {item_cd}: {len(rout_counts)}ê°œ ROUT_NO ë°œê²¬")
                    all_results[item_cd] = item_routing
            else:
                for item_cd in batch_codes:
                    all_results[item_cd] = pd.DataFrame()
                    
        except Exception as exc:
            logger.error("[DB] ë¼ìš°íŒ… ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤íŒ¨ (ë°°ì¹˜ %s): %s", i // batch_size + 1, exc)
            for item_cd in batch_codes:
                all_results[item_cd] = pd.DataFrame()
    
    found_count = len([k for k, v in all_results.items() if not v.empty])
    logger.info("[DB] ë¼ìš°íŒ… ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: %sê°œ ìš”ì²­, %sê°œ ë°œê²¬", 
               len(item_codes), found_count)
    
    return all_results

def fetch_work_results_batch(item_codes: List[str]) -> Dict[str, pd.DataFrame]:
    """ğŸš€ ì—¬ëŸ¬ í’ˆëª©ì˜ ì‘ì—… ê²°ê³¼ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì¡°íšŒ"""
    if not item_codes:
        return {}
    
    item_codes = [code.upper() for code in item_codes]
    
    # Access DBì˜ IN ì ˆ ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 100
    all_results = {}
    
    for i in range(0, len(item_codes), batch_size):
        batch_codes = item_codes[i:i + batch_size]
        placeholders = ','.join('?' * len(batch_codes))
        
        query = f'''
            SELECT *
            FROM {VIEW_WORK_RESULT}
            WHERE ITEM_CD IN ({placeholders})
        '''
        
        logger.debug("[DB] WORK_RESULT ë°°ì¹˜ ì¡°íšŒ: %sê°œ í’ˆëª© (ë°°ì¹˜ %s)", 
                    len(batch_codes), i // batch_size + 1)
        
        try:
            df = _run_query_optimized(query, batch_codes)
                
            if not df.empty:
                # í’ˆëª©ë³„ë¡œ DataFrame ë¶„ë¦¬
                for item_cd in batch_codes:
                    item_results = df[df['ITEM_CD'] == item_cd].copy()
                    all_results[item_cd] = item_results
            else:
                # ë¹ˆ ê²°ê³¼ì¸ ê²½ìš°ì—ë„ í’ˆëª©ë³„ë¡œ ë¹ˆ DataFrame ìƒì„±
                for item_cd in batch_codes:
                    all_results[item_cd] = pd.DataFrame()
                    
        except Exception as exc:
            logger.error("[DB] ì‘ì—…ê²°ê³¼ ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤íŒ¨ (ë°°ì¹˜ %s): %s", i // batch_size + 1, exc)
            # ì‹¤íŒ¨í•œ ë°°ì¹˜ì˜ í’ˆëª©ë“¤ì€ ë¹ˆ DataFrameìœ¼ë¡œ ì²˜ë¦¬
            for item_cd in batch_codes:
                all_results[item_cd] = pd.DataFrame()
    
    found_count = len([k for k, v in all_results.items() if not v.empty])
    logger.info("[DB] ì‘ì—…ê²°ê³¼ ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: %sê°œ ìš”ì²­, %sê°œ ë°œê²¬", 
               len(item_codes), found_count)
    
    return all_results

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8) ğŸ’¡ ê³ ê¸‰ ë°°ì¹˜ ì¡°íšŒ (í•„ìš”ì‹œ ì‚¬ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_all_data_batch(item_codes: List[str], latest_routing_only: bool = True) -> Dict[str, Dict[str, pd.DataFrame]]:
    """
    ğŸš€ ëª¨ë“  ê´€ë ¨ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì¡°íšŒ - ìµœê³  ì„±ëŠ¥ ìµœì í™”
    
    Args:
        item_codes: í’ˆëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        latest_routing_only: Trueì¼ ê²½ìš° ê° í’ˆëª©ì˜ ìµœì‹  ë¼ìš°íŒ…ë§Œ í¬í•¨ (ê¸°ë³¸ê°’ True)
    
    Returns:
        Dict[str, Dict[str, pd.DataFrame]]: í’ˆëª©ë³„ ëª¨ë“  ë°ì´í„°
    """
    if not item_codes:
        return {}
    
    logger.info("[DB] ì „ì²´ ë°ì´í„° ë°°ì¹˜ ì¡°íšŒ ì‹œì‘: %sê°œ í’ˆëª©", len(item_codes))
    
    # ë³‘ë ¬ë¡œ ëª¨ë“  ë°ì´í„° ì¡°íšŒ
    items_data = fetch_items_batch(item_codes)
    routings_data = fetch_routings_for_items(item_codes, latest_only=latest_routing_only)
    work_results_data = fetch_work_results_batch(item_codes)
    
    # í’ˆëª©ë³„ë¡œ ëª¨ë“  ë°ì´í„° í†µí•©
    result = {}
    for item_cd in item_codes:
        item_cd_upper = item_cd.upper()
        result[item_cd_upper] = {
            'item_master': items_data.get(item_cd_upper, pd.DataFrame()),
            'routing': routings_data.get(item_cd_upper, pd.DataFrame()),
            'work_results': work_results_data.get(item_cd_upper, pd.DataFrame())
        }
    
    logger.info("[DB] ì „ì²´ ë°ì´í„° ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: %sê°œ í’ˆëª©", len(item_codes))
    return result

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9) ğŸ”§ ì—°ê²° í…ŒìŠ¤íŠ¸ ë° ìœ í‹¸ë¦¬í‹°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_connection() -> bool:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        with _connect() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT TOP 1 ITEM_CD FROM " + VIEW_ITEM_MASTER)
            result = cursor.fetchone()
            logger.info("[DB] ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ: %s", result[0] if result else "ë°ì´í„° ì—†ìŒ")
            return True
    except Exception as exc:
        logger.error("[DB] ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: %s", exc)
        return False

def get_database_info() -> Dict[str, Any]:
    """ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ"""
    try:
        db_path = _latest_db(ACCESS_DIR)
        with _connect() as conn:
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ì •ë³´ ì¡°íšŒ
            tables_info = {}
            for view_name in [VIEW_ITEM_MASTER, VIEW_ROUTING, VIEW_WORK_RESULT]:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {view_name}")
                    count = cursor.fetchone()[0]
                    tables_info[view_name] = count
                except Exception as e:
                    tables_info[view_name] = f"ì¡°íšŒ ì‹¤íŒ¨: {e}"
            
            return {
                'database_path': str(db_path),
                'database_size_mb': round(db_path.stat().st_size / 1024 / 1024, 2),
                'tables_info': tables_info,
                'connection_status': 'ì •ìƒ'
            }
    except Exception as exc:
        logger.error("[DB] ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: %s", exc)
        return {
            'connection_status': f'ì˜¤ë¥˜: {exc}',
            'database_path': 'ì•Œ ìˆ˜ ì—†ìŒ',
            'database_size_mb': 0,
            'tables_info': {}
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10) ì¶”ê°€ í•¨ìˆ˜ë“¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def check_item_has_routing(item_cd: str) -> bool:
    """í’ˆëª©ì˜ ë¼ìš°íŒ… ì¡´ì¬ ì—¬ë¶€ í™•ì¸ - ëŒ€ì†Œë¬¸ì ë¬´ì‹œ"""
    item_cd_upper = item_cd.upper().strip()
    
    query = f"""
        SELECT COUNT(*) as cnt
        FROM {VIEW_ROUTING}
        WHERE ITEM_CD = ?
    """
    
    try:
        result = _run_query(query, [item_cd_upper])
        
        return result['cnt'].iloc[0] > 0 if not result.empty else False
        
    except Exception as e:
        logger.error(f"[DB] ë¼ìš°íŒ… ì¡´ì¬ í™•ì¸ ì˜¤ë¥˜: {str(e)}")
        return False
    
def fetch_item_info_only(item_cd: str) -> pd.DataFrame:
    """
    í’ˆëª© ì •ë³´ë§Œ ì¡°íšŒ (ë¼ìš°íŒ… ì—†ì´)
    
    Args:
        item_cd: í’ˆëª© ì½”ë“œ
        
    Returns:
        pd.DataFrame: í’ˆëª© ì •ë³´
    """
    query = f"""
    SELECT *
    FROM {VIEW_ITEM_MASTER}
    WHERE ITEM_CD = ?
    """
    return _run_query(query, [item_cd.upper()])  # ëŒ€ë¬¸ì ë³€í™˜ ì¶”ê°€

def fetch_routing_statistics(latest_only: bool = True) -> pd.DataFrame:
    """
    ë¼ìš°íŒ… í†µê³„ ì •ë³´ ì¡°íšŒ (í’ˆëª©ë³„ ê³µì • ìˆ˜, í‰ê·  ì‹œê°„ ë“±)
    
    Args:
        latest_only: Trueì¼ ê²½ìš° ê° í’ˆëª©ì˜ ìµœì‹  ROUT_NOë§Œ ì‚¬ìš© (ê¸°ë³¸ê°’ True)
    
    Returns:
        pd.DataFrame: í†µê³„ ì •ë³´
    """
    if latest_only:
        # ìµœì‹  ROUT_NOë§Œ ì‚¬ìš©í•œ í†µê³„
        query = f"""
        WITH LatestRouting AS (
            SELECT r1.*
            FROM {VIEW_ROUTING} r1
            INNER JOIN (
                SELECT ITEM_CD, MAX(INSRT_DT) as MAX_DT
                FROM {VIEW_ROUTING}
                GROUP BY ITEM_CD
            ) r2 ON r1.ITEM_CD = r2.ITEM_CD AND r1.INSRT_DT = r2.MAX_DT
        )
        SELECT 
            ITEM_CD,
            ROUT_NO,
            COUNT(DISTINCT PROC_SEQ) as PROCESS_COUNT,
            SUM(SETUP_TIME + RUN_TIME) as TOTAL_TIME,
            AVG(SETUP_TIME + RUN_TIME) as AVG_TIME_PER_PROCESS,
            MAX(PROC_SEQ) as MAX_PROC_SEQ
        FROM LatestRouting
        GROUP BY ITEM_CD, ROUT_NO
        """
    else:
        # ëª¨ë“  ROUT_NO í¬í•¨ í†µê³„
        query = f"""
        SELECT 
            ITEM_CD,
            COUNT(DISTINCT ROUT_NO) as ROUT_NO_COUNT,
            COUNT(DISTINCT PROC_SEQ) as PROCESS_COUNT,
            SUM(SETUP_TIME + RUN_TIME) as TOTAL_TIME,
            AVG(SETUP_TIME + RUN_TIME) as AVG_TIME_PER_PROCESS,
            MAX(PROC_SEQ) as MAX_PROC_SEQ
        FROM {VIEW_ROUTING}
        GROUP BY ITEM_CD
        """
    
    return _run_query(query)

def get_distinct_rout_nos(item_cd: str) -> List[str]:
    """
    íŠ¹ì • í’ˆëª©ì˜ ëª¨ë“  ROUT_NO ëª©ë¡ ì¡°íšŒ
    
    Args:
        item_cd: í’ˆëª© ì½”ë“œ
        
    Returns:
        List[str]: ROUT_NO ëª©ë¡ (ìµœì‹ ìˆœ)
    """
    query = f"""
        SELECT DISTINCT ROUT_NO, MAX(INSRT_DT) as LATEST_DT
        FROM {VIEW_ROUTING}
        WHERE ITEM_CD = ?
        GROUP BY ROUT_NO
        ORDER BY MAX(INSRT_DT) DESC
    """
    
    try:
        df = _run_query(query, [item_cd.upper()])
        return df['ROUT_NO'].tolist() if not df.empty else []
    except Exception as e:
        logger.error(f"[DB] ROUT_NO ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
        return []

def fetch_routing_by_rout_no(item_cd: str, rout_no: str) -> pd.DataFrame:
    """
    íŠ¹ì • ROUT_NOì˜ ë¼ìš°íŒ… ì •ë³´ ì¡°íšŒ
    
    Args:
        item_cd: í’ˆëª© ì½”ë“œ
        rout_no: ë¼ìš°íŒ… ë²ˆí˜¸
        
    Returns:
        pd.DataFrame: ë¼ìš°íŒ… ì •ë³´
    """
    query = f"""
        SELECT *
        FROM {VIEW_ROUTING}
        WHERE ITEM_CD = ? AND ROUT_NO = ?
        ORDER BY PROC_SEQ
    """
    
    logger.debug(f"[DB] íŠ¹ì • ROUT_NO ë¼ìš°íŒ… ì¡°íšŒ: {item_cd}, {rout_no}")
    return _run_query(query, [item_cd.upper(), rout_no])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11) ì •ë¦¬ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def cleanup_connections():
    """ì—°ê²° í’€ ì •ë¦¬"""
    try:
        with _connection_pool.lock:
            for conn in _connection_pool.connections:
                try:
                    conn.close()
                except Exception:
                    pass
            _connection_pool.connections.clear()
        logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"ì—°ê²° í’€ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# ëª¨ë“ˆ ì¢…ë£Œ ì‹œ ìë™ ì •ë¦¬
atexit.register(cleanup_connections)
