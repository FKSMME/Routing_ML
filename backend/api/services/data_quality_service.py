"""ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤."""
from __future__ import annotations

import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field
from sqlalchemy import func, text
from sqlalchemy.orm import Session

from backend.database import get_session
from backend.models.items import Item
from common.logger import get_logger

logger = get_logger(__name__)


# ============================================================================
# Models
# ============================================================================


class DataQualityMetrics(BaseModel):
    """ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­."""

    timestamp: datetime = Field(..., description="ì¸¡ì • ì‹œê°„")
    total_items: int = Field(..., description="ì´ í’ˆëª© ìˆ˜")
    complete_items: int = Field(..., description="ì™„ì „í•œ í’ˆëª© ìˆ˜")
    incomplete_items: int = Field(..., description="ë¶ˆì™„ì „í•œ í’ˆëª© ìˆ˜")
    completeness_rate: float = Field(..., description="ì™„ì „ì„± ë¹„ìœ¨ (0-1)")

    # í•„ë“œë³„ ê²°ì¸¡ì¹˜
    missing_material_code: int = Field(0, description="ì¬ì§ˆ ì½”ë“œ ê²°ì¸¡")
    missing_part_type: int = Field(0, description="í’ˆëª© ìœ í˜• ê²°ì¸¡")
    missing_dimensions: int = Field(0, description="ì¹˜ìˆ˜ ì •ë³´ ê²°ì¸¡")
    missing_drawing_number: int = Field(0, description="ë„ë©´ë²ˆí˜¸ ê²°ì¸¡")

    # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ (0-100)
    quality_score: float = Field(..., description="ì „ì²´ í’ˆì§ˆ ì ìˆ˜")

    # ì¤‘ë³µ ê²€ì‚¬
    duplicate_items: int = Field(0, description="ì¤‘ë³µ í’ˆëª© ìˆ˜")
    duplicate_drawing_numbers: int = Field(0, description="ì¤‘ë³µ ë„ë©´ë²ˆí˜¸ ìˆ˜")

    # ì´ìƒì¹˜ ê²€ì‚¬
    outlier_dimensions: int = Field(0, description="ì¹˜ìˆ˜ ì´ìƒì¹˜ ìˆ˜")
    invalid_formats: int = Field(0, description="í˜•ì‹ ì˜¤ë¥˜ ìˆ˜")

    # ìµœê·¼ ë³€ê²½ ì‚¬í•­
    items_added_24h: int = Field(0, description="ìµœê·¼ 24ì‹œê°„ ì¶”ê°€ëœ í’ˆëª©")
    items_updated_24h: int = Field(0, description="ìµœê·¼ 24ì‹œê°„ ìˆ˜ì •ëœ í’ˆëª©")
    items_deleted_24h: int = Field(0, description="ìµœê·¼ 24ì‹œê°„ ì‚­ì œëœ í’ˆëª©")


class DataQualityIssue(BaseModel):
    """ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ."""

    issue_id: str = Field(..., description="ì´ìŠˆ ID")
    severity: str = Field(..., description="ì‹¬ê°ë„ (critical/high/medium/low)")
    category: str = Field(..., description="ì¹´í…Œê³ ë¦¬ (missing/duplicate/outlier/invalid)")
    description: str = Field(..., description="ì´ìŠˆ ì„¤ëª…")
    affected_items: int = Field(..., description="ì˜í–¥ë°›ëŠ” í’ˆëª© ìˆ˜")
    sample_item_ids: List[int] = Field(..., description="ìƒ˜í”Œ í’ˆëª© ID (ìµœëŒ€ 5ê°œ)")
    detected_at: datetime = Field(..., description="íƒì§€ ì‹œê°„")
    recommendation: str = Field(..., description="ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­")


class DataQualityReport(BaseModel):
    """ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œ."""

    report_id: str = Field(..., description="ë³´ê³ ì„œ ID")
    generated_at: datetime = Field(..., description="ìƒì„± ì‹œê°„")
    metrics: DataQualityMetrics = Field(..., description="í’ˆì§ˆ ë©”íŠ¸ë¦­")
    issues: List[DataQualityIssue] = Field(..., description="ë°œê²¬ëœ ì´ìŠˆ ëª©ë¡")
    recommendations: List[str] = Field(..., description="ì „ì²´ ê¶Œì¥ì‚¬í•­")
    trend: Optional[Dict[str, Any]] = Field(None, description="ì¶”ì„¸ ì •ë³´")


class ComponentHealth(BaseModel):
    """ë‹¨ì¼ êµ¬ì„± ìš”ì†Œ ìƒíƒœ."""

    status: str = Field(..., description="healthy | degraded | unhealthy")
    message: Optional[str] = Field(None, description="ìƒíƒœ ë©”ì‹œì§€")
    last_check: datetime = Field(..., description="ë§ˆì§€ë§‰ ì ê²€ ì‹œê°„")


class HealthStatus(BaseModel):
    """ë°ì´í„° í’ˆì§ˆ ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ."""

    status: str = Field(..., description="healthy | degraded | unhealthy")
    components: Dict[str, ComponentHealth] = Field(..., description="êµ¬ì„± ìš”ì†Œë³„ ìƒíƒœ")
    timestamp: datetime = Field(..., description="ìƒíƒœ ì¸¡ì • ì‹œê°")


# ============================================================================
# Data Quality Service
# ============================================================================


class DataQualityService:
    """ë°ì´í„° í’ˆì§ˆ ì¸¡ì • ë° ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤."""

    def __init__(self, session: Session):
        self.session = session

    def collect_metrics(self) -> DataQualityMetrics:
        """í˜„ì¬ ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        logger.info("ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘")
        start_time = time.time()

        try:
            # ì´ í’ˆëª© ìˆ˜
            total_items = self.session.query(func.count(Item.id)).scalar() or 0

            # ì™„ì „ì„± ê²€ì‚¬
            complete_items = self._count_complete_items()
            incomplete_items = total_items - complete_items
            completeness_rate = complete_items / total_items if total_items > 0 else 0.0

            # í•„ë“œë³„ ê²°ì¸¡ì¹˜
            missing_material_code = self._count_missing_field("material_code")
            missing_part_type = self._count_missing_field("part_type")
            missing_dimensions = self._count_missing_dimensions()
            missing_drawing_number = self._count_missing_field("drawing_number")

            # ì¤‘ë³µ ê²€ì‚¬
            duplicate_items = self._count_duplicate_items()
            duplicate_drawing_numbers = self._count_duplicate_drawing_numbers()

            # ì´ìƒì¹˜ ê²€ì‚¬
            outlier_dimensions = self._count_outlier_dimensions()
            invalid_formats = self._count_invalid_formats()

            # ìµœê·¼ ë³€ê²½ ì‚¬í•­
            items_added_24h = self._count_recent_items("created_at")
            items_updated_24h = self._count_recent_items("updated_at")
            items_deleted_24h = 0  # soft delete ë¯¸êµ¬í˜„ ì‹œ 0

            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)
            quality_score = self._calculate_quality_score(
                completeness_rate=completeness_rate,
                duplicate_rate=duplicate_items / total_items if total_items > 0 else 0,
                outlier_rate=outlier_dimensions / total_items if total_items > 0 else 0,
                invalid_rate=invalid_formats / total_items if total_items > 0 else 0,
            )

            metrics = DataQualityMetrics(
                timestamp=datetime.now(),
                total_items=total_items,
                complete_items=complete_items,
                incomplete_items=incomplete_items,
                completeness_rate=completeness_rate,
                missing_material_code=missing_material_code,
                missing_part_type=missing_part_type,
                missing_dimensions=missing_dimensions,
                missing_drawing_number=missing_drawing_number,
                quality_score=quality_score,
                duplicate_items=duplicate_items,
                duplicate_drawing_numbers=duplicate_drawing_numbers,
                outlier_dimensions=outlier_dimensions,
                invalid_formats=invalid_formats,
                items_added_24h=items_added_24h,
                items_updated_24h=items_updated_24h,
                items_deleted_24h=items_deleted_24h,
            )

            elapsed = time.time() - start_time
            logger.info(f"ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")
            return metrics

        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            raise

    def detect_issues(self, metrics: DataQualityMetrics) -> List[DataQualityIssue]:
        """ë°ì´í„° í’ˆì§ˆ ì´ìŠˆë¥¼ íƒì§€í•©ë‹ˆë‹¤."""
        issues: List[DataQualityIssue] = []
        now = datetime.now()

        # 1. ë†’ì€ ë¶ˆì™„ì „ì„±
        if metrics.completeness_rate < 0.7:
            issues.append(
                DataQualityIssue(
                    issue_id=f"INCOMPLETE_{now.strftime('%Y%m%d%H%M%S')}",
                    severity="critical" if metrics.completeness_rate < 0.5 else "high",
                    category="missing",
                    description=f"í’ˆëª© ì™„ì „ì„±ì´ ë‚®ìŠµë‹ˆë‹¤ ({metrics.completeness_rate*100:.1f}%)",
                    affected_items=metrics.incomplete_items,
                    sample_item_ids=self._get_incomplete_item_samples(),
                    detected_at=now,
                    recommendation="í•„ìˆ˜ í•„ë“œ(ì¬ì§ˆ, í’ˆëª©ìœ í˜•, ì¹˜ìˆ˜)ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”",
                )
            )

        # 2. ì¬ì§ˆ ì½”ë“œ ê²°ì¸¡
        if metrics.missing_material_code > 0:
            severity = "critical" if metrics.missing_material_code > metrics.total_items * 0.3 else "high"
            issues.append(
                DataQualityIssue(
                    issue_id=f"MISSING_MATERIAL_{now.strftime('%Y%m%d%H%M%S')}",
                    severity=severity,
                    category="missing",
                    description=f"ì¬ì§ˆ ì½”ë“œê°€ ëˆ„ë½ëœ í’ˆëª©ì´ {metrics.missing_material_code}ê°œ ìˆìŠµë‹ˆë‹¤",
                    affected_items=metrics.missing_material_code,
                    sample_item_ids=self._get_missing_field_samples("material_code"),
                    detected_at=now,
                    recommendation="ì¬ì§ˆ ì½”ë“œë¥¼ í‘œì¤€ ì½”ë“œë¡œ ì…ë ¥í•´ì£¼ì„¸ìš” (STS, AL, SM ë“±)",
                )
            )

        # 3. ì¤‘ë³µ í’ˆëª©
        if metrics.duplicate_items > 0:
            issues.append(
                DataQualityIssue(
                    issue_id=f"DUPLICATE_{now.strftime('%Y%m%d%H%M%S')}",
                    severity="medium",
                    category="duplicate",
                    description=f"ì¤‘ë³µ í’ˆëª©ì´ {metrics.duplicate_items}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                    affected_items=metrics.duplicate_items,
                    sample_item_ids=self._get_duplicate_item_samples(),
                    detected_at=now,
                    recommendation="ì¤‘ë³µ í’ˆëª©ì„ ë³‘í•©í•˜ê±°ë‚˜ ì‚­ì œí•´ì£¼ì„¸ìš”",
                )
            )

        # 4. ì¹˜ìˆ˜ ì´ìƒì¹˜
        if metrics.outlier_dimensions > 0:
            issues.append(
                DataQualityIssue(
                    issue_id=f"OUTLIER_{now.strftime('%Y%m%d%H%M%S')}",
                    severity="medium",
                    category="outlier",
                    description=f"ì¹˜ìˆ˜ ì´ìƒì¹˜ê°€ {metrics.outlier_dimensions}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                    affected_items=metrics.outlier_dimensions,
                    sample_item_ids=self._get_outlier_dimension_samples(),
                    detected_at=now,
                    recommendation="ì¹˜ìˆ˜ ê°’ì„ í™•ì¸í•˜ê³  ì˜¤ë¥˜ê°€ ìˆë‹¤ë©´ ìˆ˜ì •í•´ì£¼ì„¸ìš”",
                )
            )

        # 5. í˜•ì‹ ì˜¤ë¥˜
        if metrics.invalid_formats > 0:
            issues.append(
                DataQualityIssue(
                    issue_id=f"INVALID_FORMAT_{now.strftime('%Y%m%d%H%M%S')}",
                    severity="high",
                    category="invalid",
                    description=f"í˜•ì‹ ì˜¤ë¥˜ê°€ {metrics.invalid_formats}ê°œ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                    affected_items=metrics.invalid_formats,
                    sample_item_ids=self._get_invalid_format_samples(),
                    detected_at=now,
                    recommendation="ë„ë©´ë²ˆí˜¸, ì½”ë“œ ë“±ì˜ í˜•ì‹ì„ í‘œì¤€ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”",
                )
            )

        return issues

    def generate_report(self) -> DataQualityReport:
        """ë°ì´í„° í’ˆì§ˆ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        metrics = self.collect_metrics()
        issues = self.detect_issues(metrics)

        # ì „ì²´ ê¶Œì¥ì‚¬í•­
        recommendations = self._generate_recommendations(metrics, issues)

        report = DataQualityReport(
            report_id=f"DQR_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            generated_at=datetime.now(),
            metrics=metrics,
            issues=issues,
            recommendations=recommendations,
            trend=None,  # ì¶”ì„¸ëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”
        )

        return report

    # ========================================================================
    # Private Helper Methods
    # ========================================================================

    def _count_complete_items(self) -> int:
        """ì™„ì „í•œ í’ˆëª© ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (í•„ìˆ˜ í•„ë“œê°€ ëª¨ë‘ ìˆëŠ” í’ˆëª©)."""
        # í•„ìˆ˜ í•„ë“œ: material_code, part_type, ìµœì†Œ 1ê°œ ì´ìƒì˜ ì¹˜ìˆ˜
        count = (
            self.session.query(func.count(Item.id))
            .filter(
                Item.material_code.isnot(None),
                Item.material_code != "",
                Item.part_type.isnot(None),
                Item.part_type != "",
            )
            .scalar()
            or 0
        )
        return count

    def _count_missing_field(self, field_name: str) -> int:
        """íŠ¹ì • í•„ë“œì˜ ê²°ì¸¡ì¹˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        field = getattr(Item, field_name)
        count = (
            self.session.query(func.count(Item.id))
            .filter((field.is_(None)) | (field == ""))
            .scalar()
            or 0
        )
        return count

    def _count_missing_dimensions(self) -> int:
        """ì¹˜ìˆ˜ ì •ë³´ê°€ ì—†ëŠ” í’ˆëª© ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        count = (
            self.session.query(func.count(Item.id))
            .filter(
                (Item.inner_diameter.is_(None)),
                (Item.outer_diameter.is_(None)),
                (Item.thickness.is_(None)),
            )
            .scalar()
            or 0
        )
        return count

    def _count_duplicate_items(self) -> int:
        """ì¤‘ë³µ í’ˆëª© ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (ë™ì¼í•œ ì¬ì§ˆ+í’ˆëª©ìœ í˜•+ì¹˜ìˆ˜)."""
        # êµ¬í˜„ ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ì„ì‹œë¡œ 0 ë°˜í™˜
        # ì‹¤ì œë¡œëŠ” GROUP BY + HAVING COUNT(*) > 1 ì‚¬ìš©
        return 0

    def _count_duplicate_drawing_numbers(self) -> int:
        """ì¤‘ë³µ ë„ë©´ë²ˆí˜¸ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        result = (
            self.session.query(func.count())
            .select_from(
                self.session.query(Item.drawing_number)
                .filter(Item.drawing_number.isnot(None), Item.drawing_number != "")
                .group_by(Item.drawing_number)
                .having(func.count(Item.id) > 1)
                .subquery()
            )
            .scalar()
            or 0
        )
        return result

    def _count_outlier_dimensions(self) -> int:
        """ì¹˜ìˆ˜ ì´ìƒì¹˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (í‰ê·  Â± 3Ïƒ ë²—ì–´ë‚œ ê°’)."""
        # ê°„ë‹¨í•œ êµ¬í˜„: ë¹„í˜„ì‹¤ì ìœ¼ë¡œ í° ê°’ (10000mm ì´ìƒ)
        count = (
            self.session.query(func.count(Item.id))
            .filter(
                (Item.inner_diameter > 10000)
                | (Item.outer_diameter > 10000)
                | (Item.thickness > 1000)
            )
            .scalar()
            or 0
        )
        return count

    def _count_invalid_formats(self) -> int:
        """í˜•ì‹ ì˜¤ë¥˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        # ì˜ˆ: ë„ë©´ë²ˆí˜¸ê°€ íŠ¹ìˆ˜ë¬¸ìë§Œìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš°
        # ì‹¤ì œë¡œëŠ” ì •ê·œì‹ ê²€ì‚¬ í•„ìš”
        return 0

    def _count_recent_items(self, timestamp_field: str) -> int:
        """ìµœê·¼ 24ì‹œê°„ ì´ë‚´ í’ˆëª© ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        field = getattr(Item, timestamp_field, None)
        if field is None:
            return 0

        cutoff = datetime.now() - timedelta(hours=24)
        count = (
            self.session.query(func.count(Item.id))
            .filter(field >= cutoff)
            .scalar()
            or 0
        )
        return count

    def _calculate_quality_score(
        self,
        completeness_rate: float,
        duplicate_rate: float,
        outlier_rate: float,
        invalid_rate: float,
    ) -> float:
        """í’ˆì§ˆ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (0-100)."""
        # ê°€ì¤‘ í‰ê· 
        score = (
            completeness_rate * 40  # ì™„ì „ì„± 40%
            + (1 - duplicate_rate) * 20  # ì¤‘ë³µ ì—†ìŒ 20%
            + (1 - outlier_rate) * 20  # ì´ìƒì¹˜ ì—†ìŒ 20%
            + (1 - invalid_rate) * 20  # í˜•ì‹ ì˜¤ë¥˜ ì—†ìŒ 20%
        ) * 100
        return max(0.0, min(100.0, score))

    def _get_incomplete_item_samples(self) -> List[int]:
        """ë¶ˆì™„ì „í•œ í’ˆëª© ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        items = (
            self.session.query(Item.id)
            .filter(
                (Item.material_code.is_(None))
                | (Item.material_code == "")
                | (Item.part_type.is_(None))
                | (Item.part_type == "")
            )
            .limit(5)
            .all()
        )
        return [item.id for item in items]

    def _get_missing_field_samples(self, field_name: str) -> List[int]:
        """íŠ¹ì • í•„ë“œê°€ ëˆ„ë½ëœ í’ˆëª© ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        field = getattr(Item, field_name)
        items = (
            self.session.query(Item.id)
            .filter((field.is_(None)) | (field == ""))
            .limit(5)
            .all()
        )
        return [item.id for item in items]

    def _get_duplicate_item_samples(self) -> List[int]:
        """ì¤‘ë³µ í’ˆëª© ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        return []  # êµ¬í˜„ ë³µì¡ì„±ìœ¼ë¡œ ì¸í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    def _get_outlier_dimension_samples(self) -> List[int]:
        """ì¹˜ìˆ˜ ì´ìƒì¹˜ ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        items = (
            self.session.query(Item.id)
            .filter(
                (Item.inner_diameter > 10000)
                | (Item.outer_diameter > 10000)
                | (Item.thickness > 1000)
            )
            .limit(5)
            .all()
        )
        return [item.id for item in items]

    def _get_invalid_format_samples(self) -> List[int]:
        """í˜•ì‹ ì˜¤ë¥˜ ìƒ˜í”Œì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        return []

    def _generate_recommendations(
        self, metrics: DataQualityMetrics, issues: List[DataQualityIssue]
    ) -> List[str]:
        """ì „ì²´ ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        recommendations = []

        if metrics.quality_score < 70:
            recommendations.append("âš ï¸ ì „ì²´ ë°ì´í„° í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë°ì´í„° ì •ì œ ì‘ì—…ì´ ì‹œê¸‰í•©ë‹ˆë‹¤.")

        if metrics.completeness_rate < 0.8:
            recommendations.append("ğŸ“ í•„ìˆ˜ í•„ë“œ(ì¬ì§ˆ, í’ˆëª©ìœ í˜•, ì¹˜ìˆ˜) ì…ë ¥ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

        if metrics.duplicate_items > 0:
            recommendations.append("ğŸ”„ ì¤‘ë³µ í’ˆëª©ì„ ì •ë¦¬í•˜ì—¬ ë°ì´í„° ì¼ê´€ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.")

        if len(issues) > 5:
            recommendations.append("ğŸ” ë°œê²¬ëœ ì´ìŠˆê°€ ë§ìŠµë‹ˆë‹¤. ìš°ì„ ìˆœìœ„ë³„ë¡œ í•´ê²°í•´ì£¼ì„¸ìš”.")

        if not recommendations:
            recommendations.append("âœ… ë°ì´í„° í’ˆì§ˆì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”.")

        return recommendations

    def get_health_status(self) -> HealthStatus:
        """ë°ì´í„° í’ˆì§ˆ íŒŒì´í”„ë¼ì¸ì˜ ì „ë°˜ì ì¸ ìƒíƒœë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
        now = datetime.now()

        # Database ì—°ê²° ìƒíƒœ
        try:
            self.session.execute(text("SELECT 1"))
            database_status = ComponentHealth(
                status="healthy",
                message="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì •ìƒì…ë‹ˆë‹¤.",
                last_check=now,
            )
        except Exception as exc:  # noqa: BLE001
            logger.exception("ë°ì´í„° í’ˆì§ˆ í—¬ìŠ¤ì²´í¬(DB) ì‹¤íŒ¨: %s", exc)
            database_status = ComponentHealth(
                status="unhealthy",
                message=f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {exc}",
                last_check=now,
            )

        # API ìƒíƒœ: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì´ ì„±ê³µí•˜ë©´ healthy, ì‹¤íŒ¨í•˜ë©´ degraded
        try:
            metrics = self.collect_metrics()
            recent_activity = f"ìµœê·¼ 24ì‹œê°„ ì‹ ê·œ {metrics.items_added_24h}ê±´ Â· ìˆ˜ì • {metrics.items_updated_24h}ê±´"
            api_status = ComponentHealth(
                status="healthy",
                message=f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì„±ê³µ. {recent_activity}",
                last_check=now,
            )
        except Exception as exc:  # noqa: BLE001
            api_status = ComponentHealth(
                status="degraded",
                message=f"í’ˆì§ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {exc}",
                last_check=now,
            )

        # Worker ìƒíƒœ: í˜„ì¬ëŠ” ê°„ì ‘ ì§€í‘œë¡œ íŒë‹¨ (ì¶”í›„ ë©”ì‹œì§€ í ì—°ë™ ì˜ˆì •)
        worker_status = ComponentHealth(
            status="healthy",
            message="ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì í ì§€ì—° ì—†ìŒ",
            last_check=now,
        )

        component_map = {
            "database": database_status,
            "api": api_status,
            "workers": worker_status,
        }

        if any(component.status == "unhealthy" for component in component_map.values()):
            overall_status = "unhealthy"
        elif any(component.status == "degraded" for component in component_map.values()):
            overall_status = "degraded"
        else:
            overall_status = "healthy"

        return HealthStatus(status=overall_status, components=component_map, timestamp=now)


# ============================================================================
# Prometheus Metrics (for export)
# ============================================================================


def get_prometheus_metrics(metrics: DataQualityMetrics) -> str:
    """Prometheus í˜•ì‹ìœ¼ë¡œ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    lines = [
        "# HELP data_quality_score Data quality score (0-100)",
        "# TYPE data_quality_score gauge",
        f"data_quality_score {metrics.quality_score}",
        "",
        "# HELP data_completeness_rate Data completeness rate (0-1)",
        "# TYPE data_completeness_rate gauge",
        f"data_completeness_rate {metrics.completeness_rate}",
        "",
        "# HELP data_total_items Total number of items",
        "# TYPE data_total_items gauge",
        f"data_total_items {metrics.total_items}",
        "",
        "# HELP data_incomplete_items Number of incomplete items",
        "# TYPE data_incomplete_items gauge",
        f"data_incomplete_items {metrics.incomplete_items}",
        "",
        "# HELP data_duplicate_items Number of duplicate items",
        "# TYPE data_duplicate_items gauge",
        f"data_duplicate_items {metrics.duplicate_items}",
        "",
        "# HELP data_outlier_dimensions Number of outlier dimensions",
        "# TYPE data_outlier_dimensions gauge",
        f"data_outlier_dimensions {metrics.outlier_dimensions}",
        "",
        "# HELP data_items_added_24h Items added in last 24 hours",
        "# TYPE data_items_added_24h gauge",
        f"data_items_added_24h {metrics.items_added_24h}",
        "",
    ]
    return "\n".join(lines)
