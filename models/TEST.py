"""
D:\routing\machine\modelsì˜ ìƒì„¸ ëª¨ë¸ ì •ë³´ í™•ì¸
"""

import sys
import joblib
import numpy as np
from pathlib import Path
from datetime import datetime

# backend ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, r"D:\routing\machine")

def check_model_details():
    """ëª¨ë¸ ìƒì„¸ ì •ë³´ í™•ì¸"""
    
    model_path = Path(r"D:\routing\machine\models")
    
    print("=" * 80)
    print("ğŸ” ML ëª¨ë¸ ìƒì„¸ ì •ë³´ ë¶„ì„")
    print("=" * 80)
    print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"ğŸ• í™•ì¸ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    if not model_path.exists():
        print("âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        return
    
    # 1. Feature Columns í™•ì¸
    print("\nğŸ“‹ [1] Feature Columns (íŠ¹ì„± ëª©ë¡)")
    print("-" * 60)
    try:
        feature_columns = joblib.load(model_path / "feature_columns.joblib")
        print(f"ì´ íŠ¹ì„± ìˆ˜: {len(feature_columns)}ê°œ\n")
        
        # íŠ¹ì„±ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
        numeric_features = []
        categorical_features = []
        
        # ì¼ë°˜ì ì¸ ìˆ˜ì¹˜í˜• íŠ¹ì„± í‚¤ì›Œë“œ
        numeric_keywords = ['QTY', 'AMT', 'COST', 'PRICE', 'RATE', 'CNT', 'NO', 'WEIGHT', 'SIZE']
        
        for feat in feature_columns:
            if any(keyword in feat.upper() for keyword in numeric_keywords):
                numeric_features.append(feat)
            else:
                categorical_features.append(feat)
        
        print(f"ë²”ì£¼í˜• íŠ¹ì„±: {len(categorical_features)}ê°œ")
        for i, feat in enumerate(categorical_features[:10], 1):
            print(f"  {i:2d}. {feat}")
        if len(categorical_features) > 10:
            print(f"  ... ì™¸ {len(categorical_features)-10}ê°œ")
        
        print(f"\nìˆ˜ì¹˜í˜• íŠ¹ì„±: {len(numeric_features)}ê°œ")
        for i, feat in enumerate(numeric_features[:10], 1):
            print(f"  {i:2d}. {feat}")
        if len(numeric_features) > 10:
            print(f"  ... ì™¸ {len(numeric_features)-10}ê°œ")
            
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 2. Encoder ì •ë³´
    print("\n\nğŸ”¤ [2] Encoder (ë²”ì£¼í˜• ì¸ì½”ë”)")
    print("-" * 60)
    try:
        encoder = joblib.load(model_path / "encoder.joblib")
        print(f"ì¸ì½”ë” íƒ€ì…: {type(encoder).__name__}")
        
        if hasattr(encoder, 'categories_'):
            print(f"ì¸ì½”ë”©ëœ íŠ¹ì„± ìˆ˜: {len(encoder.categories_)}ê°œ")
            
            # ê° íŠ¹ì„±ì˜ ê³ ìœ ê°’ ìˆ˜
            unique_counts = [len(cats) for cats in encoder.categories_]
            print("\nì¹´í…Œê³ ë¦¬ í†µê³„:")
            print(f"  - ìµœì†Œ ê³ ìœ ê°’ ìˆ˜: {min(unique_counts)}ê°œ")
            print(f"  - ìµœëŒ€ ê³ ìœ ê°’ ìˆ˜: {max(unique_counts)}ê°œ")
            print(f"  - í‰ê·  ê³ ìœ ê°’ ìˆ˜: {np.mean(unique_counts):.1f}ê°œ")
            print(f"  - ì¤‘ì•™ê°’: {np.median(unique_counts):.0f}ê°œ")
            
            # ê³ ìœ ê°’ì´ ë§ì€ íŠ¹ì„± Top 5
            if len(categorical_features) > 0:
                print("\nê³ ìœ ê°’ì´ ê°€ì¥ ë§ì€ íŠ¹ì„± Top 5:")
                cat_counts = list(zip(categorical_features[:len(encoder.categories_)], unique_counts))
                cat_counts.sort(key=lambda x: x[1], reverse=True)
                for i, (feat, count) in enumerate(cat_counts[:5], 1):
                    print(f"  {i}. {feat}: {count}ê°œ ì¹´í…Œê³ ë¦¬")
                    
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 3. Scaler ì •ë³´
    print("\n\nğŸ“Š [3] Scaler (ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ëŸ¬)")
    print("-" * 60)
    try:
        scaler = joblib.load(model_path / "scaler.joblib")
        print(f"ìŠ¤ì¼€ì¼ëŸ¬ íƒ€ì…: {type(scaler).__name__}")
        
        if hasattr(scaler, 'mean_') and hasattr(scaler, 'scale_'):
            print(f"ìŠ¤ì¼€ì¼ë§ëœ íŠ¹ì„± ìˆ˜: {len(scaler.mean_)}ê°œ")
            
            print("\ní†µê³„ ì •ë³´:")
            print(f"  - í‰ê· ê°’ ë²”ìœ„: [{scaler.mean_.min():.4f}, {scaler.mean_.max():.4f}]")
            print(f"  - í‘œì¤€í¸ì°¨ ë²”ìœ„: [{scaler.scale_.min():.4f}, {scaler.scale_.max():.4f}]")
            
            # ìŠ¤ì¼€ì¼ì´ í° íŠ¹ì„± (ë³€ë™ì„±ì´ í° íŠ¹ì„±)
            if len(scaler.scale_) > 0 and len(numeric_features) > 0:
                scale_indices = np.argsort(scaler.scale_)[::-1][:5]
                print("\në³€ë™ì„±ì´ í° íŠ¹ì„± Top 5:")
                for i, idx in enumerate(scale_indices, 1):
                    if idx < len(numeric_features):
                        print(f"  {i}. {numeric_features[idx]}: Ïƒ={scaler.scale_[idx]:.4f}")
                        
    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 4. Similarity Engine ì •ë³´
    print("\n\nğŸ” [4] Similarity Engine (ìœ ì‚¬ë„ ê²€ìƒ‰ ì—”ì§„)")
    print("-" * 60)
    try:
        # backend ëª¨ë“ˆì´ ìˆëŠ”ì§€ í™•ì¸
        try:
            searcher = joblib.load(model_path / "similarity_engine.joblib")
            print(f"ê²€ìƒ‰ ì—”ì§„ íƒ€ì…: {type(searcher).__name__}")
            
            if hasattr(searcher, 'item_codes'):
                print(f"ì¸ë±ì‹±ëœ í’ˆëª© ìˆ˜: {len(searcher.item_codes):,}ê°œ")
                
                # í’ˆëª© ì½”ë“œ ìƒ˜í”Œ
                print("\ní’ˆëª© ì½”ë“œ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):")
                for i, code in enumerate(searcher.item_codes[:10], 1):
                    print(f"  {i:2d}. {code}")
                    
            if hasattr(searcher, 'item_vectors'):
                print("\në²¡í„° ì •ë³´:")
                print(f"  - Shape: {searcher.item_vectors.shape}")
                print(f"  - ë°ì´í„° íƒ€ì…: {searcher.item_vectors.dtype}")
                print(f"  - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {searcher.item_vectors.nbytes / (1024*1024):.2f} MB")
                
                # ë²¡í„° ë…¸ë¦„ í†µê³„
                norms = np.linalg.norm(searcher.item_vectors, axis=1)
                print("\në²¡í„° ë…¸ë¦„ í†µê³„:")
                print(f"  - ìµœì†Œ: {norms.min():.4f}")
                print(f"  - ìµœëŒ€: {norms.max():.4f}")
                print(f"  - í‰ê· : {norms.mean():.4f}")
                print(f"  - í‘œì¤€í¸ì°¨: {norms.std():.4f}")
                
        except ImportError:
            print("âš ï¸ backend ëª¨ë“ˆì„ importí•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")
            obj = joblib.load(model_path / "similarity_engine.joblib")
            print(f"ê°ì²´ íƒ€ì…: {type(obj).__name__}")
            print(f"íŒŒì¼ í¬ê¸°: {(model_path / 'similarity_engine.joblib').stat().st_size / (1024*1024):.2f} MB")

    except Exception as e:
        print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # 5. ì¶”ê°€ íŒŒì¼ í™•ì¸
    print("\n\nğŸ“ [5] ê¸°íƒ€ íŒŒì¼")
    print("-" * 60)
    
    # feature_weights.npy
    weights_path = model_path / "feature_weights.npy"
    if weights_path.exists():
        try:
            weights = np.load(weights_path)
            print("âœ… feature_weights.npy")
            print(f"   - Shape: {weights.shape}")
            print(f"   - ë²”ìœ„: [{weights.min():.4f}, {weights.max():.4f}]")
            print(f"   - í‰ê· : {weights.mean():.4f}")
        except Exception as e:
            print(f"âŒ feature_weights.npy ë¡œë“œ ì‹¤íŒ¨: {e}")
    else:
        print("âŒ feature_weights.npy íŒŒì¼ ì—†ìŒ")
    
    # item_idsì™€ item_vectors (ë ˆê±°ì‹œ)
    if (model_path / "item_ids.joblib").exists():
        print("\nğŸ“Œ ë ˆê±°ì‹œ íŒŒì¼ ë°œê²¬:")
        try:
            item_ids = joblib.load(model_path / "item_ids.joblib")
            print(f"  - item_ids.joblib: {len(item_ids):,}ê°œ í’ˆëª©")
        except Exception:
            pass

        if (model_path / "item_vectors.joblib").exists():
            try:
                vectors = joblib.load(model_path / "item_vectors.joblib")
                print(f"  - item_vectors.joblib: shape {vectors.shape}")
            except Exception:
                pass
    
    # 6. ëª¨ë¸ ìš”ì•½
    print("\n\n" + "=" * 80)
    print("ğŸ“Š ëª¨ë¸ ìš”ì•½")
    print("=" * 80)
    
    files = list(model_path.glob("*.joblib")) + list(model_path.glob("*.npy"))
    total_size = sum(f.stat().st_size for f in files) / (1024 * 1024)
    
    print(f"âœ… ì´ íŒŒì¼ ìˆ˜: {len(files)}ê°œ")
    print(f"ğŸ’¾ ì´ í¬ê¸°: {total_size:.2f} MB")
    print(f"ğŸ“… ìµœì¢… ìˆ˜ì •: {datetime.fromtimestamp(max(f.stat().st_mtime for f in files)).strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ëª¨ë¸ íƒ€ì… íŒë³„
    if (model_path / "similarity_engine.joblib").exists():
        print("ğŸ¯ ëª¨ë¸ íƒ€ì…: ML ìµœì í™” ëª¨ë¸ (Similarity Search Engine í¬í•¨)")
    else:
        print("ğŸ¯ ëª¨ë¸ íƒ€ì…: ë ˆê±°ì‹œ ëª¨ë¸")
    
    print("\nâœ¨ ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œ ê°€ëŠ¥í•œ ìƒíƒœì…ë‹ˆë‹¤.")
    print("   GUIì—ì„œ [ë¡œë“œ] ë²„íŠ¼ìœ¼ë¡œ ì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    check_model_details()
